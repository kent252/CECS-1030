{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df902097",
   "metadata": {},
   "source": [
    "\n",
    "# 💡 Lab 7: Why Do We Need Data Preprocessing?\n",
    "\n",
    "## 🎯 Objectives\n",
    "- Understand the role of preprocessing in machine learning.\n",
    "- Learn about outliers, missing values, and inconsistent feature scales.\n",
    "- Practice core preprocessing techniques in Python.\n",
    "- Observe the impact of preprocessing on model performance.\n",
    "- Use data visualization to explore, detect, and communicate data issues.\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 Section 1: What is Data Preprocessing?\n",
    "\n",
    "Machine learning models rely on **clean and consistent data** to learn effectively. However, real-world data is often **messy** — containing:\n",
    "- Outliers (extreme or abnormal values)\n",
    "- Missing data points\n",
    "- Inconsistent value scales across features\n",
    "\n",
    "**Preprocessing** helps transform raw data into a format that's easier to analyze and more suitable for training algorithms.\n",
    "\n",
    "### 🧪 Example: Raw vs. Clean Data\n",
    "```python\n",
    "import pandas as pd\n",
    "data = {\n",
    "    \"Age\": [25, 28, None, 35, 1000],\n",
    "    \"Income\": [50000, 52000, 51000, None, 49000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Raw Data:\\n\", df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Section 2: Visualizing Data to Understand It\n",
    "\n",
    "Before we clean or transform any dataset, it's essential to first **visualize it**. This helps us:\n",
    "- Detect **outliers** or anomalies\n",
    "- Understand **distribution** and spread of features\n",
    "- Identify **patterns** and relationships between variables\n",
    "\n",
    "### 🧪 Example: Visualizing Salary Distribution\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.DataFrame({\"Salary\": [50, 52, 51, 1000, 53, 49, 50]})\n",
    "sns.histplot(df[\"Salary\"], kde=True)\n",
    "plt.title(\"Distribution of Salary\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 Section 3: Why Normalize Data?\n",
    "\n",
    "Features like `age`, `income`, and `area` may be measured on **very different scales**. Some models (like KNN or SVM) calculate distances — so features with large values dominate.\n",
    "\n",
    "### 🧪 Example: Scaling a Feature\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.DataFrame({\"Income\": [48000, 50000, 52000, 60000, 100000]})\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "print(\"Normalized Income:\\n\", scaled)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 Section 4: What are Outliers?\n",
    "\n",
    "Outliers are **data points that differ significantly** from others. They can skew averages, distort visualizations, and mislead models.\n",
    "\n",
    "### 🧪 Example: Detecting Outliers with a Boxplot\n",
    "```python\n",
    "sns.boxplot(x=df[\"Salary\"])\n",
    "plt.title(\"Boxplot of Salary\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Section 5: What Happens if We Skip Preprocessing?\n",
    "\n",
    "Skipping preprocessing can result in:\n",
    "- Misleading relationships between variables\n",
    "- Poor model generalization\n",
    "- Longer training times or unstable predictions\n",
    "\n",
    "### 🧪 Example: Model Confusion Without Scaling\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Height(cm)\": [150, 160, 170, 180, 190],\n",
    "    \"Weight(kg)\": [50, 60, 65, 80, 85],\n",
    "    \"Score\": [60, 65, 70, 85, 88]\n",
    "})\n",
    "\n",
    "X = df[[\"Height(cm)\", \"Weight(kg)\"]]\n",
    "y = df[\"Score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"MAE without scaling:\", mean_absolute_error(y_test, model.predict(X_test)))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Let’s Get Started!\n",
    "Now that you understand why preprocessing and visualization are essential, it’s time to explore each technique step by step through practical tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e9eb0",
   "metadata": {},
   "source": [
    "## Lab 7 Placeholder"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
